<!-- Generated by SpecStory -->

# Modify user message for multiple stakeholders (2025-07-04 16:37Z)

_**User**_

in the basic_template.py, there are more than 1 stackholders in the user message (language, subject, type). How should we do that? Please use the basic_g as a start point.

---

_**Assistant**_

I'll help you modify the `basic_g.py` file to handle multiple parameters in the user message template, similar to how `basic_template.py` uses `{language}`, `{subject}`, and `{type}`.

Let me first examine the current `basic_g.py` file to understand its structure:


---

Read file: src/lesson02_Prompt_Engineering/lesson02010_basic_g.py

---

Now I'll create a modified version of `basic_g.py` that can handle multiple parameters like `basic_template.py`. The key changes will be:

1. Update the prompt template to use multiple parameters (`{language}`, `{subject}`, `{type}`)
2. Modify the chatbot function to extract these parameters from the user message
3. Update the invocation to pass the parameters correctly


---

```diff
  # Prompt的质量和清晰度对于获得满意的模型输出至关重要，因为它直接影响了模型对任务或问题的理解和响应。
  prompt = ChatPromptTemplate.from_messages([ 
-     ("system", "You are a warm hearted AI assistant."), # "system"是指在对话系统中代表"上帝视角"的环境、人设信息。可以提供性格设定、功能限制、对话流程、输出格式等信息。
-     ("user", "{input}") # "user"是指在对话系统中代表用户的角色或信息。它通常用于提供用户输入、需求、问题、反馈等信息。一般受到system的限制，但也存在失效的可能。
+     ("system", "你是一个热心的AI助手。"), # "system"是指在对话系统中代表"上帝视角"的环境、人设信息。可以提供性格设定、功能限制、对话流程、输出格式等信息。
+     ("user", "请用{language}给我讲一个关于{subject}的{type}。") # "user"是指在对话系统中代表用户的角色或信息。它通常用于提供用户输入、需求、问题、反馈等信息。一般受到system的限制，但也存在失效的可能。
  ])
  
```

```diff
      # Get the last user message
      last_message = state["messages"][-1]
-     # Create messages from the prompt template
-     messages = prompt.format_messages(input=last_message.content)
+     
+     # Extract parameters from the message content
+     # Assuming the message content is a dictionary-like string or we can parse it
+     # For this example, we'll use a simple approach where we expect the message
+     # to contain the parameters in a structured way
+     
+     # Method 1: If the message content is a dictionary string
+     try:
+         import ast
+         params = ast.literal_eval(last_message.content)
+         language = params.get("language", "中文")
+         subject = params.get("subject", "编程")
+         type_content = params.get("type", "故事")
+     except:
+         # Method 2: If the message content is a simple string, use default values
+         language = "中文"
+         subject = "编程"
+         type_content = "故事"
+     
+     # Create messages from the prompt template with multiple parameters
+     messages = prompt.format_messages(
+         language=language,
+         subject=subject,
+         type=type_content
+     )
+     
      # Invoke the model
      response = model.invoke(messages)
```

```diff
  graph = graph_builder.compile()
  
- # 回答问题
- _prompt = "你好，我想成为一个大语言模型应用程序员，请问我应该学习哪些知识？(用列表回答)"
- 
- # 推理
- # _prompt = "你好，我是一个程序员，名字叫陈小明，大家都叫我小明。我会Python和Java。请问我是谁？(只回答名字)"
- # _prompt = "小明有一个哥哥叫大毛，还有一个弟弟叫小毛，那么小明叫什么？" # gpt-4o-mini 有时无法正确回答，有时可以
- 
- # 生成
- # _prompt = "你好，我是一个程序员，名字叫陈小明，大家都叫我小明。请问我是谁？(用json结构回答)"
- # _prompt = """我认识一个朋友叫王明，可以通过13800138000联系到他。他住在北京市朝阳区酒仙桥中路10号电子城IT产业园区B座801室，邮编是100016。
- #     (用json结构回答，包含name, mobile, city, ditrict, details_address, zipcode这几个字段)
- #     """
- 
- # 摘要
- # _prompt = """请用白话文100字总结以下诗歌内容，尤其是诗人自身的情感：\n
- # 浔阳江头夜送客，枫叶荻花秋瑟瑟。主人下马客在船，举酒欲饮无管弦。醉不成欢惨将别，别时茫茫江浸月。
- # 忽闻水上琵琶声，主人忘归客不发。寻声暗问弹者谁，琵琶声停欲语迟。移船相近邀相见，添酒回灯重开宴。千呼万唤始出来，犹抱琵琶半遮面。转轴拨弦三两声，未成曲调先有情。弦弦掩抑声声思，似诉平生不得志。低眉信手续续弹，说尽心中无限事。轻拢慢捻抹复挑，初为《霓裳》后《六幺》。大弦嘈嘈如急雨，小弦切切如私语。嘈嘈切切错杂弹，大珠小珠落玉盘。间关莺语花底滑，幽咽泉流冰下难。冰泉冷涩弦凝绝，凝绝不通声暂歇。别有幽愁暗恨生，此时无声胜有声。银瓶乍破水浆迸，铁骑突出刀枪鸣。曲终收拨当心画，四弦一声如裂帛。东船西舫悄无言，唯见江心秋月白。
- # 沉吟放拨插弦中，整顿衣裳起敛容。自言本是京城女，家在虾蟆陵下住。十三学得琵琶成，名属教坊第一部。曲罢曾教善才服，妆成每被秋娘妒。五陵年少争缠头，一曲红绡不知数。钿头银篦击节碎，血色罗裙翻酒污。今年欢笑复明年，秋月春风等闲度。弟走从军阿姨死，暮去朝来颜色故。门前冷落鞍马稀，老大嫁作商人妇。商人重利轻别离，前月浮梁买茶去。去来江口守空船，绕船月明江水寒。夜深忽梦少年事，梦啼妆泪红阑干。
- # 我闻琵琶已叹息，又闻此语重唧唧。同是天涯沦落人，相逢何必曾相识！我从去年辞帝京，谪居卧病浔阳城。浔阳地僻无音乐，终岁不闻丝竹声。住近湓江地低湿，黄芦苦竹绕宅生。其间旦暮闻何物？杜鹃啼血猿哀鸣。春江花朝秋月夜，往往取酒还独倾。岂无山歌与村笛？呕哑嘲哳难为听。今夜闻君琵琶语，如听仙乐耳暂明。莫辞更坐弹一曲，为君翻作《琵琶行》。感我此言良久立，却坐促弦弦转急。凄凄不似向前声，满座重闻皆掩泣。座中泣下谁最多？江州司马青衫湿。
- # # """
+ # Example 1: Using dictionary format for parameters
+ _prompt = '{"language": "Chinese", "subject": "dogs", "type": "short poem"}'
+ 
+ # Example 2: Using simple string (will use default values)
+ # _prompt = "Tell me a story about cats"
  
- # 数学计算（LLM的数学计算能力有限，不建议使用。如有需要，参考后期的agent与tools部分。）
- # _prompt = "请问121+212等于多少？（只要最终答案数字，不要包含任何解释、标点符号等）"
+ # Example 3: Using different parameters
+ # _prompt = '{"language": "English", "subject": "programming", "type": "joke"}'
  
  # Invoke the graph with the prompt 使用提示词调用图
```

---

Now let me create a more advanced version that can handle multiple input formats and provide better parameter extraction. I'll create a new file that demonstrates different ways to handle multiple parameters:


---

```diff
- 
+ # 1. 演示使用参数化模板，限制用户输入的问题，以便更好地引导用户输入。
+ # 使用LangGraph方式处理多个参数
+ 
+ from langchain_openai import ChatOpenAI
+ from langchain_core.prompts import ChatPromptTemplate
+ from langchain_core.output_parsers import StrOutputParser
+ 
+ # Load the API key from the .env file 从.env文件中加载API密钥
+ from dotenv import load_dotenv, find_dotenv
+ load_dotenv(find_dotenv())
+ 
+ # LangGraph imports
+ from typing import Annotated
+ from typing_extensions import TypedDict
+ from langgraph.graph import StateGraph, START, END
+ from langgraph.graph.message import add_messages
+ from langchain_core.messages import HumanMessage, SystemMessage
+ import json
+ import re
+ 
+ # Define the state structure 定义状态结构
+ class State(TypedDict):
+     messages: Annotated[list, add_messages]
+ 
+ # Prompt: create a prompt 创建提示词
+ prompt = ChatPromptTemplate.from_messages([
+     ("system", "你是一个热心的AI助手。"),
+     ("user", "请用{language}给我讲一个关于{subject}的{type}。") # 使用参数化模板，限制用户输入的问题，以便更好地引导用户输入。
+ ])
+ 
+ # Model: Create the OpenAI chatbot 创建聊天机器人
+ llm = ChatOpenAI(model="gpt-4o-mini")
+ 
+ # OutputParser: Create an output parser 创建输出解析器
+ output_parser = StrOutputParser()
+ 
+ # Create the graph builder 创建图构建器
+ graph_builder = StateGraph(State)
+ 
+ # Define the chatbot node function 定义聊天机器人节点函数
+ def chatbot(state: State):
+     # Get the last user message
+     last_message = state["messages"][-1]
+     
+     # Extract parameters from the message content
+     # Method 1: Try to parse as JSON
+     try:
+         params = json.loads(last_message.content)
+         language = params.get("language", "中文")
+         subject = params.get("subject", "编程")
+         type_content = params.get("type", "故事")
+     except json.JSONDecodeError:
+         # Method 2: Try to parse using regex pattern matching
+         # Look for patterns like "language: English" or "language=English"
+         content = last_message.content
+         
+         # Extract language
+         lang_match = re.search(r'language[:\s=]+([^\s,}]+)', content, re.IGNORECASE)
+         language = lang_match.group(1) if lang_match else "中文"
+         
+         # Extract subject
+         subj_match = re.search(r'subject[:\s=]+([^\s,}]+)', content, re.IGNORECASE)
+         subject = subj_match.group(1) if subj_match else "编程"
+         
+         # Extract type
+         type_match = re.search(r'type[:\s=]+([^\s,}]+)', content, re.IGNORECASE)
+         type_content = type_match.group(1) if type_match else "故事"
+     
+     # Create messages from the prompt template with multiple parameters
+     messages = prompt.format_messages(
+         language=language,
+         subject=subject,
+         type=type_content
+     )
+     
+     # Invoke the model
+     response = llm.invoke(messages)
+     return {"messages": [response]}
+ 
+ # Add the chatbot node to the graph 将聊天机器人节点添加到图中
+ graph_builder.add_node("chatbot", chatbot)
+ 
+ # Add edges 添加边
+ graph_builder.add_edge(START, "chatbot")
+ graph_builder.add_edge("chatbot", END)
+ 
+ # Compile the graph 编译图
+ graph = graph_builder.compile()
+ 
+ # Example 1: Using JSON format (recommended)
+ _prompt = '{"language": "Chinese", "subject": "dogs", "type": "short poem"}'
+ 
+ # Example 2: Using key-value format
+ # _prompt = 'language: English, subject: cats, type: joke'
+ 
+ # Example 3: Using simple format
+ # _prompt = 'language=English subject=programming type=story'
+ 
+ # Example 4: Using the same format as basic_template.py
+ # _prompt = '{"type": "short poem", "subject": "dogs", "language": "Chinese"}'
+ 
+ # Invoke the graph with the prompt 使用提示词调用图
+ result = graph.invoke({
+     "messages": [HumanMessage(content=_prompt)]
+ })
+ 
+ # Print the response 打印回复
+ print(result["messages"][-1].content) 
```

---

Perfect! I've created two solutions for handling multiple parameters in LangGraph:

## Summary of Changes

### 1. **Modified `basic_g.py`** 
- Updated the prompt template to use multiple parameters: `{language}`, `{subject}`, and `{type}`
- Modified the `chatbot` function to extract these parameters from the user message
- Added parameter extraction logic that can handle both dictionary strings and fallback to default values

### 2. **Created `lesson02011-1_basic_template_g.py`**
- A more advanced version that demonstrates multiple ways to handle parameter extraction
- Supports JSON format (recommended)
- Supports key-value format parsing
- Includes regex pattern matching for flexible input formats

## Key Differences from `basic_template.py`

The main difference is how parameters are passed:

**In `basic_template.py` (simple approach):**
```python
chain.invoke({"type": "short poem", "subject": "dogs", "language": "Chinese"})
```

**In the LangGraph versions:**
```python
# Parameters are passed through the message content
result = graph.invoke({
    "messages": [HumanMessage(content='{"language": "Chinese", "subject": "dogs", "type": "short poem"}')]
})
```

## How to Use Multiple Parameters

You can now use the modified `basic_g.py` or the new `lesson02011-1_basic_template_g.py` with different input formats:

1. **JSON format (recommended):**
   ```python
   _prompt = '{"language": "Chinese", "subject": "dogs", "type": "short poem"}'
   ```

2. **Key-value format:**
   ```python
   _prompt = 'language: English, subject: cats, type: joke'
   ```

3. **Simple format:**
   ```python
   _prompt = 'language=English subject=programming type=story'
   ```

The system will automatically extract the parameters and use them in the prompt template, just like in `basic_template.py` but using the LangGraph architecture.

---

