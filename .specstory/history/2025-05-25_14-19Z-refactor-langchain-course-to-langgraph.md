<!-- Generated by SpecStory -->

# Refactor langchain course to langgraph (2025-05-25 14:19Z)

_**User**_

I'm refacting the langchain based ai course into a langgraph based course (which ends with _g). Reuse the model type (OpenAI rather than Anthropic) and env loading (log_dotenv), but use the Langgraph structure (State, graph_builder, tools, chatbot, etc). Take this as reference: from typing import Annotated

from typing_extensions import TypedDict

from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages


class State(TypedDict):
    # Messages have the type "list". The `add_messages` function
    # in the annotation defines how this state key should be updated
    # (in this case, it appends messages to the list, rather than overwriting them)
    messages: Annotated[list, add_messages]


graph_builder = StateGraph(State), llm = init_chat_model("openai:gpt-4.1") def chatbot(state: State):
    return {"messages": [llm.invoke(state["messages"])]}


# The first argument is the unique node name
# The second argument is the function or object that will be called whenever
# the node is used.
graph_builder.add_node("chatbot", chatbot) graph_builder.add_edge(START, "chatbot") graph_builder.add_edge(START, "chatbot") graph_builder.add_edge("chatbot", END) from IPython.display import Image, display

try:
    display(Image(graph.get_graph().draw_mermaid_png()))
except Exception:
    # This requires some extra dependencies and is optional
    pass

---

_**Assistant**_

I'll help you refactor the LangChain-based course into a LangGraph-based course. Let me first examine the current file structure and then create the LangGraph version.


---

Read file: src/lesson01_Get_Started/lesson01010_hello_world_g.py

---

Now I'll refactor this into a LangGraph-based version while keeping the same functionality and comments in Chinese:


---

```diff
- # 演示如何使用OpenAI API创建一个简单的聊天机器人，以便在控制台中打印“hello world!”。
+ # 演示如何使用OpenAI API创建一个简单的聊天机器人，以便在控制台中打印"hello world!"。
  
  # Load the API key from the .env file (#010) 从.env文件中加载API密钥
  from dotenv import load_dotenv, find_dotenv
+ from typing import Annotated
+ from typing_extensions import TypedDict
+ from langgraph.graph import StateGraph, START, END
+ from langgraph.graph.message import add_messages
  from langchain_openai import ChatOpenAI
  
  # 从当前文件夹或父文件夹中加载.env文件的配置（成为全局可访问的静态变量）。
  load_dotenv(find_dotenv())
+ 
+ # Define the state structure 定义状态结构
+ class State(TypedDict):
+     # Messages have the type "list". The `add_messages` function
+     # in the annotation defines how this state key should be updated
+     # (in this case, it appends messages to the list, rather than overwriting them)
+     # 消息具有"list"类型。注释中的`add_messages`函数定义了如何更新此状态键
+     # （在这种情况下，它将消息附加到列表中，而不是覆盖它们）
+     messages: Annotated[list, add_messages]
+ 
+ # Create the graph builder 创建图构建器
+ graph_builder = StateGraph(State)
  
  # Create the OpenAI chatbot 创建聊天机器人
  # model或llm是大语言模型Large Language Model的缩写。ChatOpenAI是一个用于与OpenAI或与之兼容的其他模型交互的类。
- model = ChatOpenAI() # 默认是gpt-3.5
+ llm = ChatOpenAI()  # 默认是gpt-3.5
  
+ # Define the chatbot node function 定义聊天机器人节点函数
+ def chatbot(state: State):
      # Start the chatbot and get the response 启动聊天机器人并获得回复
- response = model.invoke("Please say 'Hello world!'")
+     response = llm.invoke(state["messages"])
+     return {"messages": [response]}
+ 
+ # Add the chatbot node to the graph 将聊天机器人节点添加到图中
+ # The first argument is the unique node name 第一个参数是唯一的节点名称
+ # The second argument is the function or object that will be called whenever the node is used
+ # 第二个参数是每当使用节点时将调用的函数或对象
+ graph_builder.add_node("chatbot", chatbot)
+ 
+ # Add edges to define the flow 添加边来定义流程
+ graph_builder.add_edge(START, "chatbot")
+ graph_builder.add_edge("chatbot", END)
+ 
+ # Compile the graph 编译图
+ graph = graph_builder.compile()
+ 
+ # Create initial message 创建初始消息
+ from langchain_core.messages import HumanMessage
+ 
+ # Invoke the graph with initial message 使用初始消息调用图
+ result = graph.invoke({
+     "messages": [HumanMessage(content="Please say 'Hello world!'")]
+ })
  
  # Print the response 打印回复
- print(response.content)
+ print(result["messages"][-1].content)
  
```

---

Perfect! I've successfully refactored the LangChain-based code into a LangGraph-based version. Here's what I changed:

## Key Changes Made:

1. **Added LangGraph imports**: Added the necessary imports for `StateGraph`, `START`, `END`, `add_messages`, and typing utilities.

2. **Defined State structure**: Created a `State` class using `TypedDict` with an annotated `messages` field that uses `add_messages` for proper message handling.

3. **Created graph builder**: Replaced the direct model invocation with a `StateGraph` structure.

4. **Defined chatbot node**: Created a `chatbot` function that takes a `State` parameter and returns the LLM response in the proper format.

5. **Built the graph**: Added the chatbot node and connected it from `START` to `END` to create a simple linear flow.

6. **Updated invocation**: Changed from direct model invocation to graph invocation with proper message formatting using `HumanMessage`.

7. **Updated output handling**: Modified the print statement to extract the content from the last message in the result.

## Maintained Features:

- ✅ Same OpenAI model usage (`ChatOpenAI`)
- ✅ Same environment loading (`load_dotenv`)
- ✅ Same functionality (says "Hello world!")
- ✅ Same Chinese comments for educational purposes
- ✅ Same output format

The refactored code now follows the LangGraph pattern you provided as reference, making it a proper foundation for building more complex graph-based AI applications while maintaining the educational value of the original course material.

---

